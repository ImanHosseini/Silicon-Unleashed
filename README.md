# Silicon-Unleashed
Final project for a vision course I took at NYU. Look in release for all code implementations, and full overview in report [here](https://github.com/ImanHosseini/Silicon-Unleashed/blob/main/Report.pdf). <br>
The idea was to do convolution over pretty much anything I could get my hands on, and in as many ways as time would allow me and compare the development experience and performance. So I took the easy task of convolution, and considered dimensions to be 128x128. The summary of performance is: on my XPS laptop my handcrafted SIMD (AVX) code (which you can see here: https://github.com/ImanHosseini/Silicon-Unleashed/blob/main/fastconv.cpp) is remarkably fast at only 70 us while numpy's optimized gaussian blur is at ~ 1000 us. One MKL turned out to be trash at around 4500 us. CUDA is around 60 us (it's a GTX 1650 Ti) and my FPGA implementation at around 3000 us (only the computation part, so the time to get data in and out not considered, as in all other measurements, also this is based on running on an Arty7 board on 50 MHz).
